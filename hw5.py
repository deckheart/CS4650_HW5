# -*- coding: utf-8 -*-
"""HW5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W07KUADpyxuP9S2zsliEP2GMiSeNdQff
"""

!pip install spacy
!pip install newsapi-python
!pip install wordcloud
!pip install matplotlib

!python -m spacy download en_core_web_lg

import spacy
import en_core_web_lg
import pickle
import pandas as pd
from spacy.lang.en import English
from collections import Counter
from string import punctuation
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from newsapi import NewsApiClient

nlp_eng = en_core_web_lg.load()
newsapi = NewsApiClient (api_key='5bf5a4f5b674417a9d729f397e5785de')

articles = []
for pagina in range(5):
  temp = newsapi.get_everything(q='coronavirus', language='en', from_param='2021-02-24',
                              to='2021-03-03', sort_by='relevancy', page=pagina+1)
  articles.append(temp)
  #print(temp)

filename = 'articlesCOVID.pckl'
pickle.dump(articles, open(filename, 'wb'))

filename = 'articlesCOVID.pckl'
loaded_model = pickle.load(open(filename, 'rb'))

filepath = 'articlesCOVID.pckl'
pickle.dump(loaded_model, open(filepath, 'wb'))

dados = []
for i, article in enumerate(articles):
    for x in article['articles']:
        title = x['title']
        date = x['publishedAt']
        description = x['description']
        content = x['content']
        #print(x)
        dados.append({'title':title, 'date':date, 'desc':description, 'content':content})
df = pd.DataFrame(dados)
df = df.dropna()
df.head()

def get_keywords_eng(content):
  result = []
  doc = nlp_eng(content)
  pos_tag = ['VERB', 'NOUN', 'PROPN']

  for token in doc:
    if(token.text in nlp_eng.Defaults.stop_words or token.text in punctuation):
      continue
    if (token.pos_ in pos_tag):
      result.append(token.text)

  return result

results = []
for content in df.desc.values:
    # use description instead of content since content is truncated
    results.append([('#' + x[0]) for x in Counter(get_keywords_eng(content)).most_common(5)])

    #for x in Counter(get_keywords_eng(content)).most_common(5):
    #  results.append('#' + x[0])
    #  print(x[0])
    #print('______________________________')
    
df['keywords'] = results

pickle.dump(df, open(filename, 'wb'))
df.to_csv(r'dataset.csv', index=False)

df.head()

text = str(results)
wordcloud = WordCloud(max_font_size=50, max_words=100, background_color="white").generate(text)
plt.figure()
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()